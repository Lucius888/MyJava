## 负载均衡
集群中的应用服务器（节点）通常被设计成无状态，用户可以请求任何一个节点。负载均衡器会根据集群中每个节点的负载情况，将用户请求转发到合适的节点上。
负载均衡器可以用来实现**高可用**以及**伸缩性**：
- 高可用：当某个节点故障时，负载均衡器会将用户请求转发到另外的节点上，从而保证所有服务持续可用；
- 伸缩性：根据系统整体负载情况，可以很容易地添加或移除节点。

负载均衡器运行过程包含两个部分：
- 根据负载均衡算法得到转发的节点；
- 进行转发。

### 负载均衡算法

#### 轮询
轮询算法把每个请求轮流发送到每个服务器上，适用于服务器性能差不多的情况；
![17a30f7bd793c1605d13da8a682e23e9.png](en-resource://database/1701:1)

#### 加权轮询

加权轮询是在轮询的基础上，根据服务器的性能差异，为服务器赋予一定的权值，性能高的服务器分配更高的权值。
![c27ecad234a4a09f2a2bcb62e673b52b.png](en-resource://database/1703:1)

#### 最少连接

最少连接算法就是将请求发送给当前最少连接数的服务器上。
#### 加权最少连接

在最少连接的基础上，根据服务器的性能为每台服务器分配权重，再根据权重计算出每台服务器能处理的连接数。
#### 随机

把请求随机发送到服务器上。和轮询算法类似，该算法比较适合服务器性能差不多的场景。
#### 源地址哈希算法
源地址哈希通过对客户端 IP 计算哈希值之后，再对服务器数量取模得到目标服务器的序号。可以保证同一 IP 的客户端的请求会转发到同一台服务器上，用来实现会话粘滞（Sticky Session）
![400f769784f1f22bf0be6c5faa8a5b3e.png](en-resource://database/1705:1)



## 缓存

在java中，缓存就是将程序或系统经常要调用的对象存在内存中，再次调用时可以快速从内存中获取对象，不必再去创建新的重复的实例。这样做可以减少系统开销，提高系统效率。
缓存的两种模式

- 内存缓存：缓存数据存放在服务器的内存空间中。
优点：速度快。
缺点：资源有限。
- 文件缓存：缓存数据存放在服务器的硬盘空间中。
优点：容量大。
缺点：速度偏慢，尤其在缓存数量巨大时。
### 为什么要用缓存

#### 高性能

对于一些需要复杂操作耗时查出来的结果，且确定后面不怎么变化，但是有很多读请求，那么直接将查询出来的结果放在缓存中，后面直接读缓存就好。
#### 高并发

对于像mysql这种数据库，一般2000qps就报警了，但是当数据请求太大的时候可以通过缓存来解决问题。

### 缓存存在的问题

#### 缓存穿透

对某一个不存在的数据进行请求，该请求会穿透缓存到达数据库
解决方法：
- 对这些不存在的数据缓存一个空数据
- 对这类请求进行过滤
#### 缓存雪崩

由于书没有加载到缓存中，或者缓存中的数据在同一时间大面积失效，又或者缓存服务器宕机，导致大量请求到底数据库，导致数据库崩溃。
解决方法：
- 为了防止缓存在同一时间大面积过期，可以通过观察客户行为合理设置缓存过期时间
- 为了防止缓存服务器宕机，可以采用分布式缓存，分布式缓存中的每一个节点只缓存部分数据，一个节点宕机不影响其他节点缓存的使用
- 缓存预热，避免系统在刚刚启动时还未将大量数据进行缓存而导致缓存雪崩
#### 缓存一致性

缓存一致性要求数据更新的同时缓存数据也能够试试更新
解决方案：
- 在数据更新的同时立即去更新缓存
- 在读取缓存之前就判断数据是否为新的，不是就先进性更新。

### 数据分布

#### 哈希分布

哈希分布就是将数据计算哈希值之后，按照哈希值分配到不同的节点上。例如有 N 个节点，数据的主键为 key，则将该数据分配的节点序号为：hash(key)%N。
传统的哈希分布算法存在一个问题：当节点数量变化时，也就是 N 值变化，那么几乎所有的数据都需要重新分布，将导致大量的数据迁移。
**解决办法就是：一致hash--Distributed Hash Table（DHT）**
将哈希空间 [0, 2n-1] 看成一个哈希环，每个服务器节点都配置到哈希环上。每个数据对象通过哈希取模得到哈希值之后，存放到哈希环中顺时针方向第一个大于等于该哈希值的节点上。这样每次插入或者删除的时候就只会影响相邻节点

#### 顺序分布

将数据划分为多个连续的部分，按数据的 ID 或者时间分布到不同节点上。
顺序分布相比于哈希分布的主要优点如下：

- 能保持数据原有的顺序；
- 并且能够准确控制每台服务器存储的数据量，从而使得存储空间的利用率最大。
### 淘汰策略

#### FIFO（First In First Out）

先进先出策略，在实时性的场景下，需要经常访问最新的数据，那么就可以使用 FIFO，使得最先进入的数据（最晚的数据）被淘汰。
#### LFU（Least Frequently Used）

最不经常使用策略，优先淘汰一段时间内使用次数最少的数据。
#### LRU（Least Recently Used）

最近最久未使用策略，优先淘汰最久未使用的数据，也就是上次被访问时间距离现在最久的数据。该策略可以保证内存中的数据都是热点数据，也就是经常被访问的数据，从而保证缓存命中率。

## 消息队列

消息队列中间件是分布式系统中重要的组件，主要解决应用解耦，异步处理，流量削锋等问题，实现高性能，高可用，可伸缩和最终一致性架构。目前使用较多的消息队列有ActiveMQ，RabbitMQ，ZeroMQ，MetaMQ，RocketMQ
两种消费模型
- 点对点模型（一条消息被一个消费者使用）：同步的
- 发布/订阅模型（一条消息被多个消费者使用）：异步的
###  消息队列的应用场景（优点）

#### 流量削峰

用户请求数量暴增，远远大于系统的处理能力（实际上就是数据库的访问能力，一般为1秒2k次数），这种情况系统就会崩溃。解决方法就是使用消息队列，用户的请求都被挤压在MQ中，系统仍然是按照最大速度去MQ中拉取消息，直到把全部消息处理完毕。

#### 应用解耦

使用MQ中间件，那么A就只需要向MQ中发送消息，不用管有没有去消费，再增加或者减少一个消费者的时候也比较方便。

#### 异步处理

发送者将消息发送给消息队列之后，不需要**同步等待**消息接收者处理（B/C/D）完毕，而是从MQ立即返回进行其它操作。

### 消息队列的缺点

#### 系统可用性降低

系统引入的外部依赖越多，越容易挂掉。本来你就是 A 系统调用 BCD 三个系统的接口就好了，ABCD 四个系统还好好的，没啥问题，你偏加个 MQ 进来，万一 MQ 挂了咋整？MQ 一挂，整套系统崩溃，你不就完了？
#### 系统复杂度提高

硬生生加个 MQ 进来，复杂度提高了。
**你怎么保证消息没有重复消费？**

- 保证接收端处理消息的业务逻辑具有幂等性：只要具有幂等性，那么消费多少次消息，最后处理的结果都是一样的。（消费消息之前判断一下消息是否被消费过了，如果是的就丢掉）
- 保证消息具有唯一编号，并使用一张日志表来记录已经消费的消息编号。
### 一致性问题
A 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，咋整？你这数据就不一致了。
### 常见的消息队列

| 特性       | RocketMQ          | RabbitMQ                    | Kafka                              |
| ---------- | ----------------- | --------------------------- | ---------------------------------- |
| 单机吞吐量 | 10W级 高吞吐      | 万级                        | 10w级 一般都是用来进行实时数据计算 |
| 时效性     | ms级              | 微秒级 最大的特点就是延迟低 | ms级                               |
| 可用性     | 非常高 分布式架构 | 高 主从架构                 | 非常高 分布式架构                  |
| 消息可靠性 | 可以做到0丢失     | 基本不丢失                  | 可以做到0丢失                      |